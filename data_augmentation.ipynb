{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy  as np \r\n",
    "import pandas as pd\r\n",
    "from processing import *\r\n",
    "from scipy.stats import truncnorm\r\n",
    "from fastai.tabular.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_truncated_normal(mean=265, sd=265, low=0, upp=500):\r\n",
    "    return truncnorm((low - mean) / sd, (upp - mean) / sd, loc=mean, scale=sd)\r\n",
    "\r\n",
    "def find_nearest(array, value):\r\n",
    "    array = np.asarray(array)\r\n",
    "    idx = (np.abs(array - value)).argmin()\r\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 256\r\n",
    "interval = 20\r\n",
    "k = 10\r\n",
    "\r\n",
    "filenames = ['avatar1', 'avengers1', 'bbc1', 'bear1', 'bighero1', 'creed1', 'edgeoftmr11', 'gunviolence1', 'ironman1', 'joe1', 'lex1', 'vox1']\r\n",
    "files = [pd.read_csv(('datasets/{}.csvprocessed.csv').format(name)) for name in filenames]\r\n",
    "\r\n",
    "data_sets = pd.concat(files, ignore_index=True).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = data_sets[\"Interest\"]\r\n",
    "    \r\n",
    "labels_norm = [1 if x == 4 or x == 5 else 0 for x in labels]\r\n",
    "\r\n",
    "data_sets[\"Interest\"] = labels_norm\r\n",
    "\r\n",
    "interested = np.array(data_sets[data_sets['Interest'] == 1])\r\n",
    "uninterested = np.array(data_sets[data_sets['Interest'] == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interestedN1 = np.array(np.array_split(np.array(np.array_split(interested[:int(len(interested)/(fs*interval))*fs*interval], int((len(interested)/(fs*interval))), axis=0)), k, axis=1)).reshape(10*-1, 512, 6)[:, :, 1:5]\r\n",
    "\r\n",
    "sortedN1 = interestedN1[np.argsort(interestedN1.reshape(-1, 512*4).sum(axis=1))]\r\n",
    "\r\n",
    "print(sortedN1.shape)\r\n",
    "\r\n",
    "mean = np.mean(sortedN1.reshape(-1, 512*4))\r\n",
    "std = np.std(sortedN1.reshape(-1, 512*4))\r\n",
    "\r\n",
    "mean_indx = find_nearest(np.mean(sortedN1.reshape(-1, 512*4), axis=1), mean)\r\n",
    "std_indx = find_nearest(np.mean(sortedN1.reshape(-1, 512*4), axis=1), std)\r\n",
    "\r\n",
    "r = get_truncated_normal(mean=mean_indx, sd=int(std_indx/2), low=0, upp=len(sortedN1))\r\n",
    "print(int(r.rvs()))\r\n",
    "\r\n",
    "new_pos_segments = []\r\n",
    "for n in range(500):\r\n",
    "    ind = [interestedN1[int(r.rvs())] for x in range(10)]\r\n",
    "    new_pos_segments.append(np.concatenate(ind, axis=0))\r\n",
    "\r\n",
    "new_pos_segments = np.array(new_pos_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uninterestedN1 = np.array(np.array_split(np.array(np.array_split(uninterested[:int(len(uninterested)/(fs*interval))*fs*interval], int((len(uninterested)/(fs*interval))), axis=0)), k, axis=1)).reshape(10*-1, 512, 6)[:, :, 1:5]\r\n",
    "\r\n",
    "sortedUN1 = uninterestedN1[np.argsort(uninterestedN1.reshape(-1, 512*4).sum(axis=1))]\r\n",
    "\r\n",
    "print(sortedUN1.shape)\r\n",
    "\r\n",
    "Umean = np.mean(sortedUN1.reshape(-1, 512*4))\r\n",
    "Ustd = np.std(sortedUN1.reshape(-1, 512*4))\r\n",
    "\r\n",
    "Umean_indx = find_nearest(np.mean(sortedUN1.reshape(-1, 512*4), axis=1), Umean)\r\n",
    "Ustd_indx = find_nearest(np.mean(sortedUN1.reshape(-1, 512*4), axis=1), Ustd)\r\n",
    "\r\n",
    "Ur = get_truncated_normal(mean=Umean_indx, sd=int(Ustd_indx/2), low=0, upp=len(sortedUN1))\r\n",
    "print(int(Ur.rvs()))\r\n",
    "\r\n",
    "\r\n",
    "new_neg_segments = []\r\n",
    "for n in range(500):\r\n",
    "    ind = [uninterestedN1[int(Ur.rvs())] for x in range(10)]\r\n",
    "    new_neg_segments.append(np.concatenate(ind, axis=0))\r\n",
    "\r\n",
    "new_neg_segments = np.array(new_neg_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_batches = np.concatenate((new_neg_segments, new_pos_segments), axis=0).reshape(-1*5120, 4, order='F')\r\n",
    "\r\n",
    "print(augmented_batches.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.concatenate((np.zeros(500), np.full(500, 1)))\r\n",
    "# print(labels.shape)\r\n",
    "\r\n",
    "features = PSD(augmented_batches, fs, filtering=True)\r\n",
    "\r\n",
    "# print(features)\r\n",
    "\r\n",
    "normalized = pd.DataFrame(descriptive_stats(features))\r\n",
    "normalized[\"label\"] = labels\r\n",
    "\r\n",
    "print(normalized.head())\r\n",
    "\r\n",
    "procs = [Categorify, FillMissing, Normalize]\r\n",
    "dls = TabularDataLoaders.from_df(df = normalized, procs=procs, cont_names=list(normalized.columns)[:-1], \r\n",
    "                                 y_names=\"label\", y_block=CategoryBlock, bs=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score = F1Score()\r\n",
    "learn = tabular_learner(dls, metrics=[accuracy])\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(30) # cbs=EarlyStoppingCallback(min_delta=0.1, patience=2)\r\n",
    "learn.recorder.plot_losses()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "980167e7b228e73714837104a7b73144c79cc317075b5eac2b4d7ac7720305e7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}