{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy  as np \r\n",
    "import pandas as pd\r\n",
    "from processing import *\r\n",
    "from scipy.stats import truncnorm\r\n",
    "from fastai.tabular.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_truncated_normal(mean=265, sd=265, low=0, upp=500):\r\n",
    "    return truncnorm((low - mean) / sd, (upp - mean) / sd, loc=mean, scale=sd)\r\n",
    "\r\n",
    "def find_nearest(array, value):\r\n",
    "    array = np.asarray(array)\r\n",
    "    idx = (np.abs(array - value)).argmin()\r\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 256\r\n",
    "interval = 20\r\n",
    "k = 10\r\n",
    "\r\n",
    "filenames = ['avatar1', 'avengers1', 'bbc1', 'bear1', 'bighero1', 'creed1', 'edgeoftmr11', 'gunviolence1', 'ironman1', 'joe1', 'lex1', 'vox1']\r\n",
    "files = [pd.read_csv(('datasets/{}.csvprocessed.csv').format(name)) for name in filenames]\r\n",
    "\r\n",
    "data_sets = pd.concat(files, ignore_index=True).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = data_sets[\"Interest\"]\r\n",
    "    \r\n",
    "labels_norm = [1 if x == 4 or x == 5 else 0 for x in labels]\r\n",
    "\r\n",
    "data_sets[\"Interest\"] = labels_norm\r\n",
    "\r\n",
    "interested = np.array(data_sets[data_sets['Interest'] == 1])\r\n",
    "uninterested = np.array(data_sets[data_sets['Interest'] == 0])\r\n",
    "\r\n",
    "# print(int(len(interested)/(fs*interval))*fs*interval)\r\n",
    "# print(int(len(interested)/(fs*interval))) #53\r\n",
    "# print(int(len(uninterested)/(fs*interval))) #41\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(530, 512, 4)\n",
      "52\n"
     ]
    }
   ],
   "source": [
    "# interestedN = np.array(np.array_split(interested[:int(len(interested)/(fs*interval))*fs*interval], int((len(interested)/(fs*interval))), axis=0))\r\n",
    "interestedN1 = np.array(np.array_split(np.array(np.array_split(interested[:int(len(interested)/(fs*interval))*fs*interval], int((len(interested)/(fs*interval))), axis=0)), k, axis=1)).reshape(10*-1, 512, 6)[:, :, 1:5]\r\n",
    "\r\n",
    "sortedN1 = interestedN1[np.argsort(interestedN1.reshape(-1, 512*4).sum(axis=1))]\r\n",
    "\r\n",
    "print(sortedN1.shape)\r\n",
    "\r\n",
    "mean = np.mean(sortedN1.reshape(-1, 512*4))\r\n",
    "std = np.std(sortedN1.reshape(-1, 512*4))\r\n",
    "\r\n",
    "mean_indx = find_nearest(np.mean(sortedN1.reshape(-1, 512*4), axis=1), mean)\r\n",
    "std_indx = find_nearest(np.mean(sortedN1.reshape(-1, 512*4), axis=1), std)\r\n",
    "\r\n",
    "r = get_truncated_normal(mean=mean_indx, sd=int(std_indx/2), low=0, upp=len(sortedN1))\r\n",
    "print(int(r.rvs()))\r\n",
    "\r\n",
    "new_pos_segments = []\r\n",
    "for n in range(500):\r\n",
    "    ind = [interestedN1[int(r.rvs())] for x in range(10)]\r\n",
    "    new_pos_segments.append(np.concatenate(ind, axis=0))\r\n",
    "\r\n",
    "new_pos_segments = np.array(new_pos_segments)\r\n",
    "# print(new_pos_segments.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(410, 512, 4)\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "uninterestedN1 = np.array(np.array_split(np.array(np.array_split(uninterested[:int(len(uninterested)/(fs*interval))*fs*interval], int((len(uninterested)/(fs*interval))), axis=0)), k, axis=1)).reshape(10*-1, 512, 6)[:, :, 1:5]\r\n",
    "\r\n",
    "sortedUN1 = uninterestedN1[np.argsort(uninterestedN1.reshape(-1, 512*4).sum(axis=1))]\r\n",
    "\r\n",
    "print(sortedUN1.shape)\r\n",
    "\r\n",
    "Umean = np.mean(sortedUN1.reshape(-1, 512*4))\r\n",
    "Ustd = np.std(sortedUN1.reshape(-1, 512*4))\r\n",
    "\r\n",
    "Umean_indx = find_nearest(np.mean(sortedUN1.reshape(-1, 512*4), axis=1), Umean)\r\n",
    "Ustd_indx = find_nearest(np.mean(sortedUN1.reshape(-1, 512*4), axis=1), Ustd)\r\n",
    "\r\n",
    "Ur = get_truncated_normal(mean=Umean_indx, sd=int(Ustd_indx/2), low=0, upp=len(sortedUN1))\r\n",
    "print(int(Ur.rvs()))\r\n",
    "\r\n",
    "\r\n",
    "new_neg_segments = []\r\n",
    "for n in range(500):\r\n",
    "    ind = [uninterestedN1[int(Ur.rvs())] for x in range(10)]\r\n",
    "    new_neg_segments.append(np.concatenate(ind, axis=0))\r\n",
    "\r\n",
    "new_neg_segments = np.array(new_neg_segments)\r\n",
    "# print(new_neg_segments.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5120000, 4)\n"
     ]
    }
   ],
   "source": [
    "augmented_batches = np.concatenate((new_neg_segments, new_pos_segments), axis=0).reshape(-1*5120, 4, order='F')\r\n",
    "\r\n",
    "print(augmented_batches.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5120000, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:14<00:00,  3.62s/it]\n",
      "100%|██████████| 1000/1000 [00:12<00:00, 77.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2         3         4         5         6  \\\n",
      "0 -1.012846 -1.183549 -0.952168 -1.057001 -0.975189 -1.065700  0.351425   \n",
      "1 -0.786426 -0.908924  0.654961 -0.871849 -1.076684 -1.190552 -0.758977   \n",
      "2 -1.096515 -1.338745  2.097281 -1.279174 -1.106541 -1.200076 -0.854891   \n",
      "3 -1.027439 -0.970438  0.559958 -1.027470 -1.031350 -1.013526  0.780325   \n",
      "4 -1.176215 -1.387097 -1.198844 -1.260419 -1.228658 -1.410788 -1.611914   \n",
      "\n",
      "          7         8         9  ...        87        88        89        90  \\\n",
      "0 -1.032129 -1.255045 -1.248234  ... -1.120615 -1.308857 -1.247570 -1.218510   \n",
      "1 -1.127477 -0.837460 -0.978745  ... -0.792518 -1.022640 -1.007990  2.090873   \n",
      "2 -1.110816 -1.020694 -1.074304  ... -1.185136 -1.150918 -1.203454  0.747225   \n",
      "3 -1.079907 -0.974324 -1.004701  ... -1.188314 -1.101107 -1.161597  2.005377   \n",
      "4 -1.277766 -1.009178 -1.265779  ... -1.046440 -0.682643 -0.786641 -0.111249   \n",
      "\n",
      "         91        92        93        94        95  label  \n",
      "0 -1.189406 -1.029234 -1.132112  1.276311 -1.141535    0.0  \n",
      "1 -1.150479 -1.030779 -0.917538  0.660160 -1.040313    0.0  \n",
      "2 -1.219037 -1.012692 -0.910277  0.277619 -1.014015    0.0  \n",
      "3 -1.199849 -1.195418 -1.060490  0.272094 -1.139509    0.0  \n",
      "4 -0.730789 -1.021354 -1.060195 -0.738590 -1.015867    0.0  \n",
      "\n",
      "[5 rows x 97 columns]\n"
     ]
    }
   ],
   "source": [
    "labels = np.concatenate((np.zeros(500), np.full(500, 1)))\r\n",
    "# print(labels.shape)\r\n",
    "\r\n",
    "features = PSD(augmented_batches, fs, filtering=True)\r\n",
    "\r\n",
    "# print(features)\r\n",
    "\r\n",
    "normalized = pd.DataFrame(descriptive_stats(features))\r\n",
    "normalized[\"label\"] = labels\r\n",
    "\r\n",
    "print(normalized.head())\r\n",
    "\r\n",
    "procs = [Categorify, FillMissing, Normalize]\r\n",
    "dls = TabularDataLoaders.from_df(df = normalized, procs=procs, cont_names=list(normalized.columns)[:-1], \r\n",
    "                                 y_names=\"label\", y_block=CategoryBlock, bs=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score = F1Score()\r\n",
    "learn = tabular_learner(dls, metrics=[accuracy])\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.733669</td>\n",
       "      <td>0.696128</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.727360</td>\n",
       "      <td>0.709919</td>\n",
       "      <td>0.485000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.709354</td>\n",
       "      <td>0.730450</td>\n",
       "      <td>0.445000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.690585</td>\n",
       "      <td>0.741675</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.669822</td>\n",
       "      <td>0.769080</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.647714</td>\n",
       "      <td>0.779813</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.634589</td>\n",
       "      <td>0.805680</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.612246</td>\n",
       "      <td>0.820162</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.592004</td>\n",
       "      <td>0.881848</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.569757</td>\n",
       "      <td>0.931046</td>\n",
       "      <td>0.465000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.546416</td>\n",
       "      <td>0.843292</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.518987</td>\n",
       "      <td>0.876035</td>\n",
       "      <td>0.465000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.492958</td>\n",
       "      <td>0.920022</td>\n",
       "      <td>0.445000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.471671</td>\n",
       "      <td>0.978242</td>\n",
       "      <td>0.465000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.447461</td>\n",
       "      <td>0.929416</td>\n",
       "      <td>0.435000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.418775</td>\n",
       "      <td>1.001805</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.387463</td>\n",
       "      <td>0.965886</td>\n",
       "      <td>0.445000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.351958</td>\n",
       "      <td>1.046945</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.323155</td>\n",
       "      <td>1.045412</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.295639</td>\n",
       "      <td>1.029741</td>\n",
       "      <td>0.465000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.268856</td>\n",
       "      <td>1.054985</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.246364</td>\n",
       "      <td>1.061690</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.224512</td>\n",
       "      <td>1.090637</td>\n",
       "      <td>0.465000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.205606</td>\n",
       "      <td>1.112151</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.189890</td>\n",
       "      <td>1.109764</td>\n",
       "      <td>0.435000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.177626</td>\n",
       "      <td>1.122800</td>\n",
       "      <td>0.445000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.169410</td>\n",
       "      <td>1.120987</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.159873</td>\n",
       "      <td>1.125362</td>\n",
       "      <td>0.430000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.153534</td>\n",
       "      <td>1.133762</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.144794</td>\n",
       "      <td>1.137637</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(30) # cbs=EarlyStoppingCallback(min_delta=0.1, patience=2)\r\n",
    "# learn.recorder.plot_losses()\r\n",
    "# algo = svm_model(normalized, labels)\r\n",
    "# search = random_search_svm(normalized, labels)\r\n",
    "# print(search.best_params_)\r\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "980167e7b228e73714837104a7b73144c79cc317075b5eac2b4d7ac7720305e7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}